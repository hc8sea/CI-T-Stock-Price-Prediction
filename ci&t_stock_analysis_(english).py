# -*- coding: utf-8 -*-
"""CI&T_Stock_Analysis_(English).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cc416oWw9_ioNRvg_xU5Ic_036J7p0cJ

# **CI&T Stock Analysis**

Recently, CI&T was listed on the New York Stock Exchange, listed as CINT.

Through this notebook, we will extract the historical series of stock prices, since the listing to the current day. With this data in hand, a model that seeks to predict future movements will be developed using Convolutional Neural Networks.

The first step is to install the necessary packages, starting with yfinance.
"""

!pip install yfinance==0.1.67

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import yfinance as yf
import pandas as pd

"""First we will access the desired action through the Ticker module and familiarize ourselves with the information available by the history function of yfinance:"""

cit = yf.Ticker("CINT")
cit_info = cit.history()
cit_info.head()

"""Now we will extract the historical price series and allocate the data that interests us in numpy arrays. 

Note that we are getting the average price of each day by the arithmetic average between the maximum and the minimum, as this metric may be more important for some analyses.
"""

cit_share_price_data = cit.history(period="max")
cit_share_price_data.head()
cit_share_price_data.reset_index(inplace=True)

series_avg = []
for i,j in zip(cit_share_price_data["High"], cit_share_price_data["Low"]):
  series_avg.append((i+j)/2)

time = []
step = 0
time_open = cit_share_price_data["Date"]
for i in time_open:
  time.append(step)
  step = step + 1
time = np.array(time)

series = []
for i in series_avg:
  i = float(i)
  series.append(i)
series = np.array(series)

def plot_series(time, series, format="-", start=0, end=None):
    plt.plot(time[start:end], series[start:end], format)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.grid(True)

plt.figure(figsize=(10, 6))
plot_series(time, series)

"""Separating data for training and validation. The last 16 days will be reserved for forecasting."""

split_time = len(time) - 16
time_train = time[:split_time]
x_train = series[:split_time]
time_valid = time[split_time:]
x_valid = series[split_time:]

window_size = 20
batch_size = 2
shuffle_buffer_size = 20

"""We have defined two important functions for training and forecasting"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[1:]))
    return ds.batch(batch_size).prefetch(1)

def model_forecast(model, series, window_size):
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size))
    ds = ds.batch(2).prefetch(1)
    forecast = model.predict(ds)
    return forecast

"""At this point, a model will be trained for 100 seasons in order to find the best Learning Rate for the Optimizer."""

tf.keras.backend.clear_session()
tf.random.set_seed(51)
np.random.seed(51)
window_size = 20
batch_size = 2
train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
print(train_set)
print(x_train.shape)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=32, kernel_size=5,
                      strides=1, padding="causal",
                      activation="relu",
                      input_shape=[None, 1]),
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.LSTM(64, return_sequences=True),
  tf.keras.layers.Dense(30, activation="relu"),
  tf.keras.layers.Dense(10, activation="relu"),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 400)
])

lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 1e-8 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.SGD(learning_rate=1e-8, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])

"""The following graph shows which Learning Rate is it."""

plt.semilogx(history.history["lr"], history.history["loss"])
plt.axis([1e-8, 1e-4, 0, 60])

"""Now we will put the best value of Lr and carry out the definitive training"""

tf.keras.backend.clear_session()
tf.random.set_seed(51)
np.random.seed(51)
#batch_size = 16
dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv1D(filters=32, kernel_size=3,
                      strides=1, padding="causal",
                      activation="relu",
                      input_shape=[None, 1]),
  tf.keras.layers.LSTM(32, return_sequences=True),
  tf.keras.layers.LSTM(32, return_sequences=True),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 200)
])

optimizer = tf.keras.optimizers.SGD(learning_rate=1e-6, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
history = model.fit(dataset,epochs=500)

"""
Running the forecast"""

rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)
rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]

"""**Finally, the result!** The orange chart represents the forecast that the Neural Network would have made of CI&T's average stock price in the last 16 days, without having contact with the actual data, and the blue chart shows the average price that actually occurred in the market over the same period of time.

This notebook can be adapted to make predictions about future days and another version of it will be included in the repository to meet this expectation.
"""

plt.figure(figsize=(10, 6))
print(time_valid)
plot_series(time_valid, x_valid)
plot_series(time_valid, rnn_forecast)

"""Here we have the error metric"""

tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()

"""And here the decrease in Loss and MAE over the 500 iterations"""

import matplotlib.image  as mpimg
import matplotlib.pyplot as plt

#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
mae=history.history['mae']
loss=history.history['loss']

epochs=range(len(loss)) # Get number of epochs

#------------------------------------------------
# Plot MAE and Loss
#------------------------------------------------
plt.plot(epochs, mae, 'r')
plt.plot(epochs, loss, 'b')
plt.title('MAE and Loss')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(["MAE", "Loss"])

plt.figure()

epochs_zoom = epochs[200:]
mae_zoom = mae[200:]
loss_zoom = loss[200:]

#------------------------------------------------
# Plot Zoomed MAE and Loss
#------------------------------------------------
plt.plot(epochs_zoom, mae_zoom, 'r')
plt.plot(epochs_zoom, loss_zoom, 'b')
plt.title('MAE and Loss')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend(["MAE", "Loss"])

plt.figure()